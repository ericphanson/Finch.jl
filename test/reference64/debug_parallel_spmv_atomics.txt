julia> @finch_code begin
        y .= 0
        for j = parallel(_)
            for i = _
                y[j] += x[i] * A[walk(i), j]
            end
        end
    end
quote
    y_lvl = (ex.bodies[1]).tns.bind.lvl
    y_lvl_2 = y_lvl.lvl
    y_lvl_3 = y_lvl_2.lvl
    y_lvl_2_val = y_lvl_2.lvl.val
    x_lvl = ((ex.bodies[2]).body.body.rhs.args[1]).tns.bind.lvl
    x_lvl_val = x_lvl.lvl.val
    A_lvl = ((ex.bodies[2]).body.body.rhs.args[2]).tns.bind.lvl
    A_lvl_2 = A_lvl.lvl
    A_lvl_ptr = A_lvl_2.ptr
    A_lvl_idx = A_lvl_2.idx
    A_lvl_2_val = A_lvl_2.lvl.val
    A_lvl_2.shape == x_lvl.shape || throw(DimensionMismatch("mismatched dimension limits ($(A_lvl_2.shape) != $(x_lvl.shape))"))
    Finch.resize_if_smaller!(y_lvl_2.atomicsArray, A_lvl.shape)
    @inbounds for idx = 1:A_lvl.shape
            lockVal = make_lock(eltype(Vector{Base.Threads.SpinLock}))
            if !(isnothing(lockVal))
                y_lvl_2.atomicsArray[idx] = lockVal
            end
        end
    Finch.resize_if_smaller!(y_lvl_2_val, A_lvl.shape)
    Finch.fill_range!(y_lvl_2_val, 0.0, 1, A_lvl.shape)
    val = y_lvl_2_val
    y_lvl_2_val = moveto(y_lvl_2_val, CPU(Threads.nthreads()))
    A_lvl_ptr = moveto(A_lvl_ptr, CPU(Threads.nthreads()))
    A_lvl_idx = moveto(A_lvl_idx, CPU(Threads.nthreads()))
    A_lvl_2_val = moveto(A_lvl_2_val, CPU(Threads.nthreads()))
    x_lvl_val = moveto(x_lvl_val, CPU(Threads.nthreads()))
    Threads.@threads for i_4 = 1:Threads.nthreads()
            phase_stop = min(A_lvl.shape, fld(A_lvl.shape * (i_4 + -1), Threads.nthreads()))
            if phase_stop >= 1
                phase_stop + 1
            end
            phase_start_2 = max(1, 1 + fld(A_lvl.shape * (i_4 + -1), Threads.nthreads()))
            phase_stop_2 = min(A_lvl.shape, fld(A_lvl.shape * i_4, Threads.nthreads()))
            if phase_stop_2 >= phase_start_2
                for j_6 = phase_start_2:phase_stop_2
                    y_lvl_q = (1 - 1) * A_lvl.shape + j_6
                    A_lvl_q = (1 - 1) * A_lvl.shape + j_6
                    y_lvl_2atomicArraysAcc = promote_val_to_lock(CPU(Threads.nthreads()), y_lvl_2.atomicsArray, y_lvl_q, eltype(Vector{Base.Threads.SpinLock}))
                    get_lock(CPU(Threads.nthreads()), y_lvl_2atomicArraysAcc)
                    A_lvl_2_q = A_lvl_ptr[A_lvl_q]
                    A_lvl_2_q_stop = A_lvl_ptr[A_lvl_q + 1]
                    if A_lvl_2_q < A_lvl_2_q_stop
                        A_lvl_2_i1 = A_lvl_idx[A_lvl_2_q_stop - 1]
                    else
                        A_lvl_2_i1 = 0
                    end
                    phase_stop_3 = min(A_lvl_2.shape, A_lvl_2_i1)
                    if phase_stop_3 >= 1
                        if A_lvl_idx[A_lvl_2_q] < 1
                            A_lvl_2_q = Finch.scansearch(A_lvl_idx, 1, A_lvl_2_q, A_lvl_2_q_stop - 1)
                        end
                        while true
                            A_lvl_2_i = A_lvl_idx[A_lvl_2_q]
                            if A_lvl_2_i < phase_stop_3
                                A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                                x_lvl_q = (1 - 1) * x_lvl.shape + A_lvl_2_i
                                x_lvl_2_val = x_lvl_val[x_lvl_q]
                                y_lvl_2_val[y_lvl_q] = y_lvl_2_val[y_lvl_q] + A_lvl_3_val * x_lvl_2_val
                                A_lvl_2_q += 1
                                A_lvl_2_i + 1
                            else
                                phase_stop_5 = min(A_lvl_2_i, phase_stop_3)
                                if A_lvl_2_i == phase_stop_5
                                    A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                                    x_lvl_q = (1 - 1) * x_lvl.shape + phase_stop_5
                                    x_lvl_2_val_2 = x_lvl_val[x_lvl_q]
                                    y_lvl_2_val[y_lvl_q] = y_lvl_2_val[y_lvl_q] + A_lvl_3_val * x_lvl_2_val_2
                                    A_lvl_2_q += 1
                                end
                                phase_stop_5 + 1
                                break
                            end
                        end
                        phase_stop_3 + 1
                    end
                    phase_start_5 = max(1, 1 + A_lvl_2_i1)
                    phase_stop_6 = A_lvl_2.shape
                    if phase_stop_6 >= phase_start_5
                        phase_stop_6 + 1
                    end
                    release_lock(CPU(Threads.nthreads()), lock)
                end
                phase_stop_2 + 1
            end
            phase_start_6 = max(1, 1 + fld(A_lvl.shape * i_4, Threads.nthreads()))
            phase_stop_7 = A_lvl.shape
            if phase_stop_7 >= phase_start_6
                phase_stop_7 + 1
            end
        end
    qos = 1 * A_lvl.shape
    resize!(y_lvl_2.atomicsArray, qos)
    resize!(val, qos)
    (y = Tensor((DenseLevel){Int64}((AtomicLevel){Vector{Base.Threads.SpinLock}, ElementLevel{0.0, Float64, Int64, Vector{Float64}}}(y_lvl_3, y_lvl_2.atomicsArray), A_lvl.shape)),)
end
julia> @finch begin
        y .= 0
        for i = parallel(_)
            for j = _
                y[j] += x[i] * A[walk(i), j]
            end
        end
    end
(y = Tensor(Dense{Int64}(Atomic([#undef, #undef], Element{0.0, Float64, Int64}([4.0, 6.0])), 2)),)

